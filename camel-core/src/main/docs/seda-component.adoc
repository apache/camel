## SEDA Component

The *seda:* component provides asynchronous
http://www.eecs.harvard.edu/~mdw/proj/seda/[SEDA] behavior, so that
messages are exchanged on a
http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/BlockingQueue.html[BlockingQueue]
and consumers are invoked in a separate thread from the producer.

Note that queues are only visible within a _single_
link:camelcontext.html[CamelContext]. If you want to communicate across
`CamelContext` instances (for example, communicating between Web
applications), see the link:vm.html[VM] component.

This component does not implement any kind of persistence or recovery,
if the VM terminates while messages are yet to be processed. If you need
persistence, reliability or distributed SEDA, try using either
link:jms.html[JMS] or link:activemq.html[ActiveMQ].

TIP:*Synchronous*
The link:direct.html[Direct] component provides synchronous invocation
of any consumers when a producer sends a message exchange.

### URI format

[source,java]
-----------------------
seda:someName[?options]
-----------------------

Where *someName* can be any string that uniquely identifies the endpoint
within the current link:camelcontext.html[CamelContext].

You can append query options to the URI in the following format:
`?option=value&option=value&â€¦`

### Options

// component options: START
The SEDA component supports 3 options which are listed below.



{% raw %}
[width="100%",cols="2,1,1m,1m,5",options="header"]
|=======================================================================
| Name | Group | Default | Java Type | Description
| queueSize | advanced |  | int | Sets the default maximum capacity of the SEDA queue (i.e. the number of messages it can hold).
| concurrentConsumers | consumer | 1 | int | Sets the default number of concurrent threads processing exchanges.
| defaultQueueFactory | advanced |  | Exchange> | Sets the default queue factory.
|=======================================================================
{% endraw %}
// component options: END


// endpoint options: START
The SEDA component supports 17 endpoint options which are listed below:

{% raw %}
[width="100%",cols="2,1,1m,1m,5",options="header"]
|=======================================================================
| Name | Group | Default | Java Type | Description
| name | common |  | String | *Required* Name of queue
| size | common | 2147483647 | int | The maximum capacity of the SEDA queue (i.e. the number of messages it can hold).
| bridgeErrorHandler | consumer | false | boolean | Allows for bridging the consumer to the Camel routing Error Handler which mean any exceptions occurred while the consumer is trying to pickup incoming messages or the likes will now be processed as a message and handled by the routing Error Handler. By default the consumer will use the org.apache.camel.spi.ExceptionHandler to deal with exceptions that will be logged at WARN/ERROR level and ignored.
| concurrentConsumers | consumer | 1 | int | Number of concurrent threads processing exchanges.
| exceptionHandler | consumer (advanced) |  | ExceptionHandler | To let the consumer use a custom ExceptionHandler. Notice if the option bridgeErrorHandler is enabled then this options is not in use. By default the consumer will deal with exceptions that will be logged at WARN/ERROR level and ignored.
| exchangePattern | consumer (advanced) |  | ExchangePattern | Sets the default exchange pattern when creating an exchange.
| limitConcurrentConsumers | consumer (advanced) | true | boolean | Whether to limit the number of concurrentConsumers to the maximum of 500. By default an exception will be thrown if an endpoint is configured with a greater number. You can disable that check by turning this option off.
| multipleConsumers | consumer (advanced) | false | boolean | Specifies whether multiple consumers are allowed. If enabled you can use SEDA for Publish-Subscribe messaging. That is you can send a message to the SEDA queue and have each consumer receive a copy of the message. When enabled this option should be specified on every consumer endpoint.
| pollTimeout | consumer (advanced) | 1000 | int | The timeout used when polling. When a timeout occurs the consumer can check whether it is allowed to continue running. Setting a lower value allows the consumer to react more quickly upon shutdown.
| purgeWhenStopping | consumer (advanced) | false | boolean | Whether to purge the task queue when stopping the consumer/route. This allows to stop faster as any pending messages on the queue is discarded.
| blockWhenFull | producer | false | boolean | Whether a thread that sends messages to a full SEDA queue will block until the queue's capacity is no longer exhausted. By default an exception will be thrown stating that the queue is full. By enabling this option the calling thread will instead block and wait until the message can be accepted.
| discardIfNoConsumers | producer | false | boolean | Whether the producer should discard the message (do not add the message to the queue) when sending to a queue with no active consumers. Only one of the options discardIfNoConsumers and failIfNoConsumers can be enabled at the same time.
| failIfNoConsumers | producer | false | boolean | Whether the producer should fail by throwing an exception when sending to a queue with no active consumers. Only one of the options discardIfNoConsumers and failIfNoConsumers can be enabled at the same time.
| timeout | producer | 30000 | long | Timeout (in milliseconds) before a SEDA producer will stop waiting for an asynchronous task to complete. You can disable timeout by using 0 or a negative value.
| waitForTaskToComplete | producer | IfReplyExpected | WaitForTaskToComplete | Option to specify whether the caller should wait for the async task to complete or not before continuing. The following three options are supported: Always Never or IfReplyExpected. The first two values are self-explanatory. The last value IfReplyExpected will only wait if the message is Request Reply based. The default option is IfReplyExpected.
| queue | advanced |  | BlockingQueue | Define the queue instance which will be used by the endpoint. This option is only for rare use-cases where you want to use a custom queue instance.
| synchronous | advanced | false | boolean | Sets whether synchronous processing should be strictly used or Camel is allowed to use asynchronous processing (if supported).
|=======================================================================
{% endraw %}
// endpoint options: END


### Choosing BlockingQueue implementation

*Available as of Camel 2.12*

By default, the SEDA component always intantiates LinkedBlockingQueue,
but you can use different implementation, you can reference your own
BlockingQueue implementation, in this case the size option is not used

[source,java]
-----------------------------------------------------------
<bean id="arrayQueue" class="java.util.ArrayBlockingQueue">
<constructor-arg index="0" value="10" ><!-- size -->
<constructor-arg index="1" value="true" ><!-- fairness -->
</bean>
<!-- ... and later -->
<from>seda:array?queue=#arrayQueue</from>
-----------------------------------------------------------

Or you can reference a BlockingQueueFactory implementation, 3
implementations are provided LinkedBlockingQueueFactory,
ArrayBlockingQueueFactory and PriorityBlockingQueueFactory:

[source,java]
-----------------------------------------------------------------------------------------------------
<bean id="priorityQueueFactory" class="org.apache.camel.component.seda.PriorityBlockingQueueFactory">
<property name="comparator">
<bean class="org.apache.camel.demo.MyExchangeComparator" />
</property>
</bean>
<!-- ... and later -->
<from>seda:priority?queueFactory=#priorityQueueFactory&size=100</from>
-----------------------------------------------------------------------------------------------------

### Use of Request Reply

The link:seda.html[SEDA] component supports using
link:request-reply.html[Request Reply], where the caller will wait for
the link:async.html[Async] route to complete. For instance:

[source,java]
-------------------------------------------------------------------------
from("mina:tcp://0.0.0.0:9876?textline=true&sync=true").to("seda:input");

from("seda:input").to("bean:processInput").to("bean:createResponse");
-------------------------------------------------------------------------

In the route above, we have a TCP listener on port 9876 that accepts
incoming requests. The request is routed to the `seda:input` queue. As
it is a link:request-reply.html[Request Reply] message, we wait for the
response. When the consumer on the `seda:input` queue is complete, it
copies the response to the original message response.

NOTE:*until 2.2: Works only with 2 endpoints*
Using link:request-reply.html[Request Reply] over link:seda.html[SEDA]
or link:vm.html[VM] only works with 2 endpoints. You *cannot* chain
endpoints by sending to A -> B -> C etc. Only between A -> B. The reason
is the implementation logic is fairly simple. To support 3+ endpoints
makes the logic much more complex to handle ordering and notification
between the waiting threads properly.
This has been improved in *Camel 2.3* onwards, which allows you to chain
as many endpoints as you like.

### Concurrent consumers

By default, the SEDA endpoint uses a single consumer thread, but you can
configure it to use concurrent consumer threads. So instead of thread
pools you can use:

[source,java]
---------------------------------------------------------
from("seda:stageName?concurrentConsumers=5").process(...)
---------------------------------------------------------

As for the difference between the two, note a _thread pool_ can
increase/shrink dynamically at runtime depending on load, whereas the
number of concurrent consumers is always fixed.

### Thread pools

Be aware that adding a thread pool to a SEDA endpoint by doing something
like:

[source,java]
---------------------------------------------
from("seda:stageName").thread(5).process(...)
---------------------------------------------

Can wind up with two `BlockQueues`: one from the SEDA endpoint, and one
from the workqueue of the thread pool, which may not be what you want.
Instead, you might wish to configure a link:direct.html[Direct] endpoint
with a thread pool, which can process messages both synchronously and
asynchronously. For example:

[source,java]
-----------------------------------------------
from("direct:stageName").thread(5).process(...)
-----------------------------------------------

You can also directly configure number of threads that process messages
on a SEDA endpoint using the `concurrentConsumers` option.

### Sample

In the route below we use the SEDA queue to send the request to this
async queue to be able to send a fire-and-forget message for further
processing in another thread, and return a constant reply in this thread
to the original caller.

Here we send a Hello World message and expects the reply to be OK.

The "Hello World" message will be consumed from the SEDA queue from
another thread for further processing. Since this is from a unit test,
it will be sent to a `mock` endpoint where we can do assertions in the
unit test.

### Using multipleConsumers

*Available as of Camel 2.2*

In this example we have defined two consumers and registered them as
spring beans.

Since we have specified *multipleConsumers=true* on the seda foo
endpoint we can have those two consumers receive their own copy of the
message as a kind of pub-sub style messaging.

As the beans are part of an unit test they simply send the message to a
mock endpoint, but notice how we can use @Consume to consume from the
seda queue.

### Extracting queue information.

If needed, information such as queue size, etc. can be obtained without
using JMX in this fashion:

[source,java]
-----------------------------------------------------
SedaEndpoint seda = context.getEndpoint("seda:xxxx");
int size = seda.getExchanges().size();
-----------------------------------------------------

### See Also

* link:configuring-camel.html[Configuring Camel]
* link:component.html[Component]
* link:endpoint.html[Endpoint]
* link:getting-started.html[Getting Started]

* link:vm.html[VM]
* link:disruptor.html[Disruptor]
* link:direct.html[Direct]
* link:async.html[Async]