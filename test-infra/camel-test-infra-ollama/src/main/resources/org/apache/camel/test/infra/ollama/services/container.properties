## ---------------------------------------------------------------------------
## Licensed to the Apache Software Foundation (ASF) under one or more
## contributor license agreements.  See the NOTICE file distributed with
## this work for additional information regarding copyright ownership.
## The ASF licenses this file to You under the Apache License, Version 2.0
## (the "License"); you may not use this file except in compliance with
## the License.  You may obtain a copy of the License at
##
##      http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.
## ---------------------------------------------------------------------------
ollama.container=mirror.gcr.io/ollama/ollama:0.12.5
ollama.model=granite4:tiny-h
# This is not really needed for ollama, but some test are using OpenAI, therefore this is handy for remote scenarios
ollama.api.key=NO_API_KEY

# Container resource limits
# CPU count (defaults to 4 cores for better performance)
# ollama.container.cpu.count=4
# Memory limit in bytes (defaults to 8GB for better performance)
# ollama.container.memory.limit=8589934592
# Enable GPU support (enabled/disabled, defaults to disabled - GPU not supported on macOS)
ollama.container.enable.gpu=disabled