/* Generated by camel build tools - do NOT edit this file! */
package org.apache.camel.component.spark;

import java.util.Map;

import org.apache.camel.CamelContext;
import org.apache.camel.spi.ExtendedPropertyConfigurerGetter;
import org.apache.camel.spi.PropertyConfigurerGetter;
import org.apache.camel.spi.ConfigurerStrategy;
import org.apache.camel.spi.GeneratedPropertyConfigurer;
import org.apache.camel.util.CaseInsensitiveMap;
import org.apache.camel.support.component.PropertyConfigurerSupport;

/**
 * Generated by camel build tools - do NOT edit this file!
 */
@SuppressWarnings("unchecked")
public class SparkEndpointConfigurer extends PropertyConfigurerSupport implements GeneratedPropertyConfigurer, PropertyConfigurerGetter {

    @Override
    public boolean configure(CamelContext camelContext, Object obj, String name, Object value, boolean ignoreCase) {
        SparkEndpoint target = (SparkEndpoint) obj;
        switch (ignoreCase ? name.toLowerCase() : name) {
        case "collect": target.setCollect(property(camelContext, boolean.class, value)); return true;
        case "dataframe":
        case "dataFrame": target.setDataFrame(property(camelContext, org.apache.spark.sql.Dataset.class, value)); return true;
        case "dataframecallback":
        case "dataFrameCallback": target.setDataFrameCallback(property(camelContext, org.apache.camel.component.spark.DataFrameCallback.class, value)); return true;
        case "lazystartproducer":
        case "lazyStartProducer": target.setLazyStartProducer(property(camelContext, boolean.class, value)); return true;
        case "rdd": target.setRdd(property(camelContext, org.apache.spark.api.java.JavaRDDLike.class, value)); return true;
        case "rddcallback":
        case "rddCallback": target.setRddCallback(property(camelContext, org.apache.camel.component.spark.RddCallback.class, value)); return true;
        case "synchronous": target.setSynchronous(property(camelContext, boolean.class, value)); return true;
        default: return false;
        }
    }

    @Override
    public Class<?> getOptionType(String name, boolean ignoreCase) {
        switch (ignoreCase ? name.toLowerCase() : name) {
        case "collect": return boolean.class;
        case "dataframe":
        case "dataFrame": return org.apache.spark.sql.Dataset.class;
        case "dataframecallback":
        case "dataFrameCallback": return org.apache.camel.component.spark.DataFrameCallback.class;
        case "lazystartproducer":
        case "lazyStartProducer": return boolean.class;
        case "rdd": return org.apache.spark.api.java.JavaRDDLike.class;
        case "rddcallback":
        case "rddCallback": return org.apache.camel.component.spark.RddCallback.class;
        case "synchronous": return boolean.class;
        default: return null;
        }
    }

    @Override
    public Object getOptionValue(Object obj, String name, boolean ignoreCase) {
        SparkEndpoint target = (SparkEndpoint) obj;
        switch (ignoreCase ? name.toLowerCase() : name) {
        case "collect": return target.isCollect();
        case "dataframe":
        case "dataFrame": return target.getDataFrame();
        case "dataframecallback":
        case "dataFrameCallback": return target.getDataFrameCallback();
        case "lazystartproducer":
        case "lazyStartProducer": return target.isLazyStartProducer();
        case "rdd": return target.getRdd();
        case "rddcallback":
        case "rddCallback": return target.getRddCallback();
        case "synchronous": return target.isSynchronous();
        default: return null;
        }
    }

    @Override
    public Object getCollectionValueType(Object target, String name, boolean ignoreCase) {
        switch (ignoreCase ? name.toLowerCase() : name) {
        case "dataframe":
        case "dataFrame": return org.apache.spark.sql.Row.class;
        default: return null;
        }
    }
}

