[[aws2-msk-component]]
= AWS Managed Streaming for Apache Kafka (MSK) Component
:docTitle: AWS Managed Streaming for Apache Kafka (MSK)
:artifactId: camel-aws2-msk
:description: Manage AWS MSK instances using AWS SDK version 2.x.
:since: 3.1
:supportLevel: Stable
:component-header: Only producer is supported
include::{cq-version}@camel-quarkus:ROOT:partial$reference/components/aws2-msk.adoc[opts=optional]
//Manually maintained attributes
:group: AWS

*Since Camel {since}*

*{component-header}*

The AWS2 MSK component supports create, run, start, stop and terminate
https://aws.amazon.com/msk/[AWS MSK] instances.

Prerequisites

You must have a valid Amazon Web Services developer account, and be
signed up to use Amazon MSK. More information is available at
https://aws.amazon.com/msk/[Amazon MSK].

== URI Format

-------------------------
aws2-msk://label[?options]
-------------------------

You can append query options to the URI in the following format,
?options=value&option2=value&...

// component-configure options: START
== Configuring Options

Camel components are configured on two separate levels:

- component level
- endpoint level

=== Configuring Component Options

The component level is the highest level which holds general and common configurations that are inherited by the endpoints.
For example a component may have security settings, credentials for authentication, urls for network connection and so forth.

Some components only have a few options, and others may have many. Because components typically have pre configured defaults
that are commonly used, then you may often only need to configure a few options on a component; or none at all.

Configuring components can be done with the xref:latest@manual::component-dsl.adoc[Component DSL],
in a configuration file (application.properties|yaml), or directly with Java code.

=== Configuring Endpoint Options

Where you find yourself configuring the most is on endpoints, as endpoints often have many options, which allows you to
configure what you need the endpoint to do. The options are also categorized into whether the endpoint is used as consumer (from)
or as a producer (to), or used for both.

Configuring endpoints is most often done directly in the endpoint URI as path and query parameters. You can also use
the xref:latest@manual::Endpoint-dsl.adoc[Endpoint DSL] as a _type safe_ way of configuring endpoints.

A good practice when configuring options is to use xref:latest@manual::using-propertyplaceholder.adoc[Property Placeholders],
which allows to not hardcode urls, port numbers, sensitive information, and other settings.
In other words placeholders allows to externalize the configuration from your code, and gives more flexibility and reuse.

The following two sections lists all the options, firstly for the component followed by the endpoint.
// component-configure options: END

// component options: START
== Component Options


The AWS Managed Streaming for Apache Kafka (MSK) component supports 16 options, which are listed below.



[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *configuration* (producer) | Component configuration |  | MSK2Configuration
| *lazyStartProducer* (producer) | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | boolean
| *mskClient* (producer) | *Autowired* To use a existing configured AWS MSK as client |  | KafkaClient
| *operation* (producer) | *Required* The operation to perform. There are 4 enums and the value can be one of: listClusters, createCluster, deleteCluster, describeCluster |  | MSK2Operations
| *overrideEndpoint* (producer) | Set the need for overidding the endpoint. This option needs to be used in combination with uriEndpointOverride option | false | boolean
| *pojoRequest* (producer) | If we want to use a POJO request as body or not | false | boolean
| *proxyHost* (producer) | To define a proxy host when instantiating the MSK client |  | String
| *proxyPort* (producer) | To define a proxy port when instantiating the MSK client |  | Integer
| *proxyProtocol* (producer) | To define a proxy protocol when instantiating the MSK client. There are 2 enums and the value can be one of: HTTP, HTTPS | HTTPS | Protocol
| *region* (producer) | The region in which MSK client needs to work. When using this parameter, the configuration will expect the lowercase name of the region (for example ap-east-1) You'll need to use the name Region.EU_WEST_1.id() |  | String
| *trustAllCertificates* (producer) | If we want to trust all certificates in case of overriding the endpoint | false | boolean
| *uriEndpointOverride* (producer) | Set the overriding uri endpoint. This option needs to be used in combination with overrideEndpoint option |  | String
| *useDefaultCredentialsProvider* (producer) | Set whether the Kafka client should expect to load credentials through a default credentials provider or to expect static credentials to be passed in. | false | boolean
| *autowiredEnabled* (advanced) | Whether autowiring is enabled. This is used for automatic autowiring options (the option must be marked as autowired) by looking up in the registry to find if there is a single instance of matching type, which then gets configured on the component. This can be used for automatic configuring JDBC data sources, JMS connection factories, AWS Clients, etc. | true | boolean
| *accessKey* (security) | Amazon AWS Access Key |  | String
| *secretKey* (security) | Amazon AWS Secret Key |  | String
|===
// component options: END

// endpoint options: START
== Endpoint Options

The AWS Managed Streaming for Apache Kafka (MSK) endpoint is configured using URI syntax:

----
aws2-msk:label
----

with the following path and query parameters:

=== Path Parameters (1 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *label* | *Required* Logical name |  | String
|===


=== Query Parameters (14 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *lazyStartProducer* (producer) | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | boolean
| *mskClient* (producer) | *Autowired* To use a existing configured AWS MSK as client |  | KafkaClient
| *operation* (producer) | *Required* The operation to perform. There are 4 enums and the value can be one of: listClusters, createCluster, deleteCluster, describeCluster |  | MSK2Operations
| *overrideEndpoint* (producer) | Set the need for overidding the endpoint. This option needs to be used in combination with uriEndpointOverride option | false | boolean
| *pojoRequest* (producer) | If we want to use a POJO request as body or not | false | boolean
| *proxyHost* (producer) | To define a proxy host when instantiating the MSK client |  | String
| *proxyPort* (producer) | To define a proxy port when instantiating the MSK client |  | Integer
| *proxyProtocol* (producer) | To define a proxy protocol when instantiating the MSK client. There are 2 enums and the value can be one of: HTTP, HTTPS | HTTPS | Protocol
| *region* (producer) | The region in which MSK client needs to work. When using this parameter, the configuration will expect the lowercase name of the region (for example ap-east-1) You'll need to use the name Region.EU_WEST_1.id() |  | String
| *trustAllCertificates* (producer) | If we want to trust all certificates in case of overriding the endpoint | false | boolean
| *uriEndpointOverride* (producer) | Set the overriding uri endpoint. This option needs to be used in combination with overrideEndpoint option |  | String
| *useDefaultCredentialsProvider* (producer) | Set whether the Kafka client should expect to load credentials through a default credentials provider or to expect static credentials to be passed in. | false | boolean
| *accessKey* (security) | Amazon AWS Access Key |  | String
| *secretKey* (security) | Amazon AWS Secret Key |  | String
|===
// endpoint options: END


Required MSK component options

You have to provide the amazonMskClient in the
Registry or your accessKey and secretKey to access
the https://aws.amazon.com/msk/[Amazon MSK] service.

== Usage

=== Static credentials vs Default Credential Provider

You have the possibility of avoiding the usage of explicit static credentials, by specifying the useDefaultCredentialsProvider option and set it to true.

 - Java system properties - aws.accessKeyId and aws.secretKey
 - Environment variables - AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.
 - Web Identity Token from AWS STS.
 - The shared credentials and config files.
 - Amazon ECS container credentials - loaded from the Amazon ECS if the environment variable AWS_CONTAINER_CREDENTIALS_RELATIVE_URI is set.
 - Amazon EC2 Instance profile credentials. 

For more information about this you can look at https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/credentials.html[AWS credentials documentation]

=== Message headers evaluated by the MSK producer

[width="100%",cols="10%,10%,80%",options="header",]
|=======================================================================
|Header |Type |Description

|`CamelAwsMSKOperation` |`String` |The operation to perform

|`CamelAwsMSKClusterFilter` |`String` |The cluster name filter for list operation

|`CamelAwsMSKClusterName` |`String` |The cluster name for list and create operation

|`CamelAwsMSKClusterArn` |`String` |The cluster arn for delete operation

|`CamelAwsMSKClusterKafkaVersion` |`String` | The Kafka for the cluster during create operation

|`CamelAwsMSKBrokerNodesNumber` |`Integer`| The number of nodes for the cluster during create operation

|`CamelAwsMSKBrokerNodesGroupInfo` |`com.amazonaws.services.kafka.model.BrokerNodeGroupInfo`| The Broker nodes group info to provide during the create operation
|=======================================================================

=== MSK Producer operations

Camel-AWS MSK component provides the following operation on the producer side:

- listClusters
- createCluster
- deleteCluster
- describeCluster

== Producer Examples

- listClusters: this operation will list the available MSK Brokers in AWS

[source,java]
--------------------------------------------------------------------------------
from("direct:listClusters")
    .to("aws2-msk://test?mskClient=#amazonMskClient&operation=listClusters")
--------------------------------------------------------------------------------

- createCluster: this operation will create an MSK Cluster in AWS

[source,java]
--------------------------------------------------------------------------------
from("direct:createCluster")
    .process(new Processor() {
       @Override
       public void process(Exchange exchange) throws Exception {
                exchange.getIn().setHeader(MSK2Constants.CLUSTER_NAME, "test-kafka");
                exchange.getIn().setHeader(MSK2Constants.CLUSTER_KAFKA_VERSION, "2.1.1");
                exchange.getIn().setHeader(MSK2Constants.BROKER_NODES_NUMBER, 2);
                BrokerNodeGroupInfo groupInfo = BrokerNodeGroupInfo.builder().build();
                exchange.getIn().setHeader(MSK2Constants.BROKER_NODES_GROUP_INFO, groupInfo);					
       }
    })
    .to("aws2-msk://test?mskClient=#amazonMskClient&operation=createCluster")
--------------------------------------------------------------------------------

- deleteCluster: this operation will delete an MSK Cluster in AWS

[source,java]
--------------------------------------------------------------------------------
from("direct:deleteCluster")
    .setHeader(MSK2Constants.CLUSTER_ARN, constant("test-kafka"));
    .to("aws2-msk://test?mskClient=#amazonMskClient&operation=deleteCluster")
--------------------------------------------------------------------------------

[source,java]
--------------------------------------------------------------------------------
from("direct:createCluster")
    .process(new Processor() {
       @Override
       public void process(Exchange exchange) throws Exception {
                exchange.getIn().setHeader(MSK2Constants.CLUSTER_NAME, "test-kafka");
                exchange.getIn().setHeader(MSK2Constants.CLUSTER_KAFKA_VERSION, "2.1.1");
                exchange.getIn().setHeader(MSK2Constants.BROKER_NODES_NUMBER, 2);
                BrokerNodeGroupInfo groupInfo = BrokerNodeGroupInfo.builder().build();
                exchange.getIn().setHeader(MSK2Constants.BROKER_NODES_GROUP_INFO, groupInfo);					
       }
    })
    .to("aws2-msk://test?mskClient=#amazonMskClient&operation=deleteCluster")
--------------------------------------------------------------------------------

== Using a POJO as body

Sometimes build an AWS Request can be complex, because of multiple options. We introduce the possibility to use a POJO as body.
In AWS MSK there are multiple operations you can submit, as an example for List clusters request, you can do something like:

[source,java]
------------------------------------------------------------------------------------------------------
from("direct:aws2-msk")
     .setBody(ListClustersRequest.builder().maxResults(10).build())
     .to("aws2-msk://test?mskClient=#amazonMskClient&operation=listClusters&pojoRequest=true")
------------------------------------------------------------------------------------------------------

In this way you'll pass the request directly without the need of passing headers and options specifically related to this operation.

== Dependencies

Maven users will need to add the following dependency to their pom.xml.

*pom.xml*

[source,xml]
---------------------------------------
<dependency>
    <groupId>org.apache.camel</groupId>
    <artifactId>camel-aws2-msk</artifactId>
    <version>${camel-version}</version>
</dependency>
---------------------------------------

where `$\{camel-version}` must be replaced by the actual version of Camel.

include::{page-component-version}@camel-spring-boot::page$aws2-msk-starter.adoc[]
