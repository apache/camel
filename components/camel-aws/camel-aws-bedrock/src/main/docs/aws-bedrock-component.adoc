= AWS Bedrock Component
:doctitle: AWS Bedrock
:shortname: aws-bedrock
:artifactid: camel-aws-bedrock
:description: Invoke Model of AWS Bedrock service.
:since: 4.5
:supportlevel: Stable
:tabs-sync-option:
:component-header: Only producer is supported
//Manually maintained attributes
:group: AWS
:camel-spring-boot-name: aws-bedrock

*Since Camel {since}*

*{component-header}*

The AWS2 Bedrock component supports invoking a supported LLM model from
https://aws.amazon.com/bedrock/[AWS Bedrock] service.

Prerequisites

You must have a valid Amazon Web Services developer account, and be
signed up to use Amazon Bedrock. More information is available at
https://aws.amazon.com/bedrock/[Amazon Bedrock].


== URI Format

-------------------------
aws-bedrock://label[?options]
-------------------------

You can append query options to the URI in the following format:

`?options=value&option2=value&...`


// component-configure options: START

// component-configure options: END

// component options: START
include::partial$component-configure-options.adoc[]
include::partial$component-endpoint-options.adoc[]
// component options: END

// endpoint options: START

// endpoint options: END


Required Bedrock component options

You have to provide the bedrockRuntimeClient in the
Registry or your accessKey and secretKey to access
the https://aws.amazon.com/bedrock/[Amazon Bedrock] service.

== Usage

=== Static credentials, Default Credential Provider and Profile Credentials Provider

You have the possibility of avoiding the usage of explicit static credentials by specifying the useDefaultCredentialsProvider option and set it to true.

The order of evaluation for Default Credentials Provider is the following:

 - Java system properties - `aws.accessKeyId` and `aws.secretKey`.
 - Environment variables - `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
 - Web Identity Token from AWS STS.
 - The shared credentials and config files.
 - Amazon ECS container credentials - loaded from the Amazon ECS if the environment variable `AWS_CONTAINER_CREDENTIALS_RELATIVE_URI` is set.
 - Amazon EC2 Instance profile credentials. 

You have also the possibility of using Profile Credentials Provider, by specifying the useProfileCredentialsProvider option to true and profileCredentialsName to the profile name.

Only one of static, default and profile credentials could be used at the same time.

For more information about this you can look at https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/credentials.html[AWS credentials documentation]

// component headers: START
include::partial$component-endpoint-headers.adoc[]
// component headers: END

=== Supported AWS Bedrock Models

- Titan Text Express V1 with id `amazon.titan-text-express-v1`
Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG).

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "inputText": {
      "type": "string"
    },
    "textGenerationConfig": {
      "type": "object",
      "properties": {
        "maxTokenCount": {
          "type": "integer"
        },
        "stopSequences": {
          "type": "array",
          "items": [
            {
              "type": "string"
            }
          ]
        },
        "temperature": {
          "type": "integer"
        },
        "topP": {
          "type": "integer"
        }
      },
      "required": [
        "maxTokenCount",
        "stopSequences",
        "temperature",
        "topP"
      ]
    }
  },
  "required": [
    "inputText",
    "textGenerationConfig"
  ]
}
--------------------------------------------------------------------------------

- Titan Text Lite V1 with id `amazon.titan-text-lite-v1`
Lite is a light weight efficient model, ideal for fine-tuning of English-language tasks.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "inputText": {
      "type": "string"
    },
    "textGenerationConfig": {
      "type": "object",
      "properties": {
        "maxTokenCount": {
          "type": "integer"
        },
        "stopSequences": {
          "type": "array",
          "items": [
            {
              "type": "string"
            }
          ]
        },
        "temperature": {
          "type": "integer"
        },
        "topP": {
          "type": "integer"
        }
      },
      "required": [
        "maxTokenCount",
        "stopSequences",
        "temperature",
        "topP"
      ]
    }
  },
  "required": [
    "inputText",
    "textGenerationConfig"
  ]
}
--------------------------------------------------------------------------------

- Titan Image Generator G1 with id `amazon.titan-image-generator-v1`
It generates images from text, and allows users to upload and edit an existing image. Users can edit an image with a text prompt (without a mask) or parts of an image with an image mask. You can extend the boundaries of an image with outpainting, and fill in an image with inpainting. 

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "textToImageParams": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string"
        },
        "negativeText": {
          "type": "string"
        }
      },
      "required": [
        "text",
        "negativeText"
      ]
    },
    "taskType": {
      "type": "string"
    },
    "imageGenerationConfig": {
      "type": "object",
      "properties": {
        "cfgScale": {
          "type": "integer"
        },
        "seed": {
          "type": "integer"
        },
        "quality": {
          "type": "string"
        },
        "width": {
          "type": "integer"
        },
        "height": {
          "type": "integer"
        },
        "numberOfImages": {
          "type": "integer"
        }
      },
      "required": [
        "cfgScale",
        "seed",
        "quality",
        "width",
        "height",
        "numberOfImages"
      ]
    }
  },
  "required": [
    "textToImageParams",
    "taskType",
    "imageGenerationConfig"
  ]
}
--------------------------------------------------------------------------------

- Titan Embeddings G1 with id `amazon.titan-embed-text-v1`
The Amazon Titan Embeddings G1 - Text – Text v1.2 can intake up to 8k tokens and outputs a vector of 1,536 dimensions. The model also works in 25+ different language

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "inputText": {
      "type": "string"
    }
  },
  "required": [
    "inputText"
  ]
}
--------------------------------------------------------------------------------

- Jurassic2-Ultra with id `ai21.j2-ultra-v1`
Jurassic-2 Ultra is AI21’s most powerful model for complex tasks that require advanced text generation and comprehension.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "prompt": {
      "type": "string"
    },
    "maxTokens": {
      "type": "integer"
    },
    "temperature": {
      "type": "integer"
    },
    "topP": {
      "type": "integer"
    },
    "stopSequences": {
      "type": "array",
      "items": [
        {
          "type": "string"
        }
      ]
    },
    "presencePenalty": {
      "type": "object",
      "properties": {
        "scale": {
          "type": "integer"
        }
      },
      "required": [
        "scale"
      ]
    },
    "frequencyPenalty": {
      "type": "object",
      "properties": {
        "scale": {
          "type": "integer"
        }
      },
      "required": [
        "scale"
      ]
    }
  },
  "required": [
    "prompt",
    "maxTokens",
    "temperature",
    "topP",
    "stopSequences",
    "presencePenalty",
    "frequencyPenalty"
  ]
}
--------------------------------------------------------------------------------

- Jurassic2-Mid with id `ai21.j2-mid-v1`
Jurassic-2 Mid is less powerful than Ultra, yet carefully designed to strike the right balance between exceptional quality and affordability.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "prompt": {
      "type": "string"
    },
    "maxTokens": {
      "type": "integer"
    },
    "temperature": {
      "type": "integer"
    },
    "topP": {
      "type": "integer"
    },
    "stopSequences": {
      "type": "array",
      "items": [
        {
          "type": "string"
        }
      ]
    },
    "presencePenalty": {
      "type": "object",
      "properties": {
        "scale": {
          "type": "integer"
        }
      },
      "required": [
        "scale"
      ]
    },
    "frequencyPenalty": {
      "type": "object",
      "properties": {
        "scale": {
          "type": "integer"
        }
      },
      "required": [
        "scale"
      ]
    }
  },
  "required": [
    "prompt",
    "maxTokens",
    "temperature",
    "topP",
    "stopSequences",
    "presencePenalty",
    "frequencyPenalty"
  ]
}
--------------------------------------------------------------------------------

- Claude Instant V1.2 with id `anthropic.claude-instant-v1`
A fast, affordable yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document question-answering.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "prompt": {
      "type": "string"
    },
    "max_tokens_to_sample": {
      "type": "integer"
    },
    "stop_sequences": {
      "type": "array",
      "items": [
        {
          "type": "string"
        }
      ]
    },
    "temperature": {
      "type": "number"
    },
    "top_p": {
      "type": "integer"
    },
    "top_k": {
      "type": "integer"
    },
    "anthropic_version": {
      "type": "string"
    }
  },
  "required": [
    "prompt",
    "max_tokens_to_sample",
    "stop_sequences",
    "temperature",
    "top_p",
    "top_k",
    "anthropic_version"
  ]
}
--------------------------------------------------------------------------------

- Claude 2 with id `anthropic.claude-v2`
Anthropic's highly capable model across a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction following.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "prompt": {
      "type": "string"
    },
    "max_tokens_to_sample": {
      "type": "integer"
    },
    "stop_sequences": {
      "type": "array",
      "items": [
        {
          "type": "string"
        }
      ]
    },
    "temperature": {
      "type": "number"
    },
    "top_p": {
      "type": "integer"
    },
    "top_k": {
      "type": "integer"
    },
    "anthropic_version": {
      "type": "string"
    }
  },
  "required": [
    "prompt",
    "max_tokens_to_sample",
    "stop_sequences",
    "temperature",
    "top_p",
    "top_k",
    "anthropic_version"
  ]
}
--------------------------------------------------------------------------------

- Claude 2.1 with id `anthropic.claude-v2:1`
An update to Claude 2 that features double the context window, plus improvements across reliability, hallucination rates, and evidence-based accuracy in long document and RAG contexts.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "prompt": {
      "type": "string"
    },
    "max_tokens_to_sample": {
      "type": "integer"
    },
    "stop_sequences": {
      "type": "array",
      "items": [
        {
          "type": "string"
        }
      ]
    },
    "temperature": {
      "type": "number"
    },
    "top_p": {
      "type": "integer"
    },
    "top_k": {
      "type": "integer"
    },
    "anthropic_version": {
      "type": "string"
    }
  },
  "required": [
    "prompt",
    "max_tokens_to_sample",
    "stop_sequences",
    "temperature",
    "top_p",
    "top_k",
    "anthropic_version"
  ]
}
--------------------------------------------------------------------------------

- Claude 3 Sonnet with id `anthropic.claude-3-sonnet-20240229-v1:0`
Claude 3 Sonnet by Anthropic strikes the ideal balance between intelligence and speed—particularly for enterprise workloads.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "messages": {
      "type": "array",
      "items": [
        {
          "type": "object",
          "properties": {
            "role": {
              "type": "string"
            },
            "content": {
              "type": "array",
              "items": [
                {
                  "type": "object",
                  "properties": {
                    "type": {
                      "type": "string"
                    },
                    "text": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "type",
                    "text"
                  ]
                }
              ]
            }
          },
          "required": [
            "role",
            "content"
          ]
        }
      ]
    },
    "max_tokens": {
      "type": "integer"
    },
    "anthropic_version": {
      "type": "string"
    }
  },
  "required": [
    "messages",
    "max_tokens",
    "anthropic_version"
  ]
}
--------------------------------------------------------------------------------

- Claude 3 Haiku with id `anthropic.claude-3-haiku-20240307-v1:0`
Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed.

Json schema for request

[source,json]
--------------------------------------------------------------------------------
{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "type": "object",
  "properties": {
    "messages": {
      "type": "array",
      "items": [
        {
          "type": "object",
          "properties": {
            "role": {
              "type": "string"
            },
            "content": {
              "type": "array",
              "items": [
                {
                  "type": "object",
                  "properties": {
                    "type": {
                      "type": "string"
                    },
                    "text": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "type",
                    "text"
                  ]
                }
              ]
            }
          },
          "required": [
            "role",
            "content"
          ]
        }
      ]
    },
    "max_tokens": {
      "type": "integer"
    },
    "anthropic_version": {
      "type": "string"
    }
  },
  "required": [
    "messages",
    "max_tokens",
    "anthropic_version"
  ]
}
--------------------------------------------------------------------------------

=== Bedrock Producer operations

Camel-AWS Bedrock component provides the following operation on the producer side:

- invokeTextModel
- invokeImageModel
- invokeEmbeddingsModel
- invokeTextModelStreaming
- invokeImageModelStreaming
- invokeEmbeddingsModelStreaming

=== Streaming Support

The streaming operations (`invokeTextModelStreaming`, `invokeImageModelStreaming`, `invokeEmbeddingsModelStreaming`) enable real-time streaming of model responses, providing lower latency and better user experience for interactive applications.

==== Streaming Output Modes

Two streaming modes are supported:

*Complete Mode (default)*: Accumulates all chunks and returns the complete response as a single message. This is the simplest mode and behaves similarly to non-streaming operations, but with lower time-to-first-token.

*Chunks Mode*: Emits each chunk as it arrives in a List. Useful for reactive streaming pipelines or when you need to process chunks individually.

==== Streaming Configuration Options

- `streamOutputMode`: Set to "complete" (default) or "chunks"
- `includeStreamingMetadata`: Whether to include metadata headers (default: true)

==== Streaming Metadata Headers

When `includeStreamingMetadata` is true, the following headers are set:

- `CamelAwsBedrockCompletionReason`: The reason the model stopped generating (e.g., "FINISH", "end_turn", "stop")
- `CamelAwsBedrockTokenCount`: The number of tokens generated (if provided by the model)
- `CamelAwsBedrockChunkCount`: The number of chunks received

==== Supported Models for Streaming

All text generation models support streaming:
- Amazon Titan (all text models)
- Anthropic Claude (all versions)
- Meta Llama (all versions)
- Mistral AI (all models)
- Cohere Command models
- Amazon Nova models

== Examples

=== Producer Examples

- invokeTextModel: this operation will invoke a model from Bedrock. This is an example for both Titan Express and Titan Lite.

[source,java]
--------------------------------------------------------------------------------
from("direct:invoke")
    .to("aws-bedrock://test?bedrockRuntimeClient=#amazonBedrockRuntimeClient&operation=invokeTextModel&modelId="
                            + BedrockModels.TITAN_TEXT_EXPRESS_V1.model))
--------------------------------------------------------------------------------

and you can then send to the direct endpoint something like

[source,java]
--------------------------------------------------------------------------------
        final Exchange result = template.send("direct:invoke", exchange -> {
            ObjectMapper mapper = new ObjectMapper();
            ObjectNode rootNode = mapper.createObjectNode();
            rootNode.put("inputText",
                    "User: Generate synthetic data for daily product sales in various categories - include row number, product name, category, date of sale and price. Produce output in JSON format. Count records and ensure there are no more than 5.");

            ArrayNode stopSequences = mapper.createArrayNode();
            stopSequences.add("User:");
            ObjectNode childNode = mapper.createObjectNode();
            childNode.put("maxTokenCount", 1024);
            childNode.put("stopSequences", stopSequences);
            childNode.put("temperature", 0).put("topP", 1);

            rootNode.put("textGenerationConfig", childNode);
            exchange.getMessage().setBody(mapper.writer().writeValueAsString(rootNode));
            exchange.getMessage().setHeader(BedrockConstants.MODEL_CONTENT_TYPE, "application/json");
            exchange.getMessage().setHeader(BedrockConstants.MODEL_ACCEPT_CONTENT_TYPE, "application/json");
        });
--------------------------------------------------------------------------------

where template is a ProducerTemplate.

- invokeImageModel: this operation will invoke a model from Bedrock. This is an example for both Titan Express and Titan Lite.

[source,java]
--------------------------------------------------------------------------------
from("direct:invoke")
    .to("aws-bedrock://test?bedrockRuntimeClient=#amazonBedrockRuntimeClient&operation=invokeImageModel&modelId="
                            + BedrockModels.TITAN_IMAGE_GENERATOR_V1.model))
                        .split(body())
                        .unmarshal().base64()
                        .setHeader("CamelFileName", simple("image-${random(128)}.png")).to("file:target/generated_images")
--------------------------------------------------------------------------------

and you can then send to the direct endpoint something like

[source,java]
--------------------------------------------------------------------------------
        final Exchange result = template.send("direct:send_titan_image", exchange -> {
            ObjectMapper mapper = new ObjectMapper();
            ObjectNode rootNode = mapper.createObjectNode();
            ObjectNode textParameter = mapper.createObjectNode();
            textParameter.putIfAbsent("text",
                    new TextNode("A Sci-fi camel running in the desert"));
            rootNode.putIfAbsent("textToImageParams", textParameter);
            rootNode.putIfAbsent("taskType", new TextNode("TEXT_IMAGE"));
            ObjectNode childNode = mapper.createObjectNode();
            childNode.putIfAbsent("numberOfImages", new IntNode(3));
            childNode.putIfAbsent("quality", new TextNode("standard"));
            childNode.putIfAbsent("cfgScale", new IntNode(8));
            childNode.putIfAbsent("height", new IntNode(512));
            childNode.putIfAbsent("width", new IntNode(512));
            childNode.putIfAbsent("seed", new IntNode(0));

            rootNode.putIfAbsent("imageGenerationConfig", childNode);

            exchange.getMessage().setBody(mapper.writer().writeValueAsString(rootNode));
            exchange.getMessage().setHeader(BedrockConstants.MODEL_CONTENT_TYPE, "application/json");
            exchange.getMessage().setHeader(BedrockConstants.MODEL_ACCEPT_CONTENT_TYPE, "application/json");
        });
--------------------------------------------------------------------------------

where template is a ProducerTemplate.

- invokeEmbeddingsModel: this operation will invoke an Embeddings model from Bedrock. This is an example for Titan Embeddings G1.

[source,java]
--------------------------------------------------------------------------------
from("direct:send_titan_embeddings")
    .to("aws-bedrock:label?useDefaultCredentialsProvider=true&region=us-east-1&operation=invokeEmbeddingsModel&modelId="
    + BedrockModels.TITAN_EMBEDDINGS_G1.model)
    .to(result);
--------------------------------------------------------------------------------

and you can then send to the direct endpoint something like

[source,java]
--------------------------------------------------------------------------------
        final Exchange result = template.send("direct:send_titan_embeddings", exchange -> {
            ObjectMapper mapper = new ObjectMapper();
            ObjectNode rootNode = mapper.createObjectNode();
            rootNode.putIfAbsent("inputText",
                    new TextNode("A Sci-fi camel running in the desert"));

            exchange.getMessage().setBody(mapper.writer().writeValueAsString(rootNode));
            exchange.getMessage().setHeader(BedrockConstants.MODEL_CONTENT_TYPE, "application/json");
            exchange.getMessage().setHeader(BedrockConstants.MODEL_ACCEPT_CONTENT_TYPE, "*/*");
        });
--------------------------------------------------------------------------------

where template is a ProducerTemplate.

- invokeTextModelStreaming (Complete Mode): this operation will invoke a model from Bedrock with streaming, accumulating the complete response.

[source,java]
--------------------------------------------------------------------------------
from("direct:stream_complete")
    .to("aws-bedrock://test?useDefaultCredentialsProvider=true&region=us-east-1"
        + "&operation=invokeTextModelStreaming&modelId=" + BedrockModels.TITAN_TEXT_EXPRESS_V1.model
        + "&streamOutputMode=complete")
    .to("log:response");
--------------------------------------------------------------------------------

and you can then send to the direct endpoint something like

[source,java]
--------------------------------------------------------------------------------
        final Exchange result = template.send("direct:stream_complete", exchange -> {
            ObjectMapper mapper = new ObjectMapper();
            ObjectNode rootNode = mapper.createObjectNode();
            rootNode.put("inputText", "Write a short poem about Apache Camel.");

            ArrayNode stopSequences = mapper.createArrayNode();
            stopSequences.add("User:");
            ObjectNode childNode = mapper.createObjectNode();
            childNode.put("maxTokenCount", 512);
            childNode.put("stopSequences", stopSequences);
            childNode.put("temperature", 0).put("topP", 1);

            rootNode.put("textGenerationConfig", childNode);
            exchange.getMessage().setBody(mapper.writer().writeValueAsString(rootNode));
            exchange.getMessage().setHeader(BedrockConstants.MODEL_CONTENT_TYPE, "application/json");
            exchange.getMessage().setHeader(BedrockConstants.MODEL_ACCEPT_CONTENT_TYPE, "application/json");
        });

        // Get the complete response
        String response = result.getMessage().getBody(String.class);

        // Get streaming metadata
        Integer tokenCount = result.getMessage().getHeader(BedrockConstants.STREAMING_TOKEN_COUNT, Integer.class);
        String completionReason = result.getMessage().getHeader(BedrockConstants.STREAMING_COMPLETION_REASON, String.class);
        Integer chunkCount = result.getMessage().getHeader(BedrockConstants.STREAMING_CHUNK_COUNT, Integer.class);
--------------------------------------------------------------------------------

- invokeTextModelStreaming (Chunks Mode): this operation will invoke a model from Bedrock with streaming, emitting individual chunks.

[source,java]
--------------------------------------------------------------------------------
from("direct:stream_chunks")
    .to("aws-bedrock://test?useDefaultCredentialsProvider=true&region=us-east-1"
        + "&operation=invokeTextModelStreaming&modelId=" + BedrockModels.ANTROPHIC_CLAUDE_V35_2.model
        + "&streamOutputMode=chunks")
    .split(body())
        .to("websocket:chat-output");  // Send each chunk to websocket
--------------------------------------------------------------------------------

and you can then send to the direct endpoint something like

[source,java]
--------------------------------------------------------------------------------
        final Exchange result = template.send("direct:stream_chunks", exchange -> {
            ObjectMapper mapper = new ObjectMapper();
            ObjectNode rootNode = mapper.createObjectNode();

            ArrayNode messages = mapper.createArrayNode();
            ObjectNode message = mapper.createObjectNode();
            message.put("role", "user");

            ArrayNode content = mapper.createArrayNode();
            ObjectNode contentBlock = mapper.createObjectNode();
            contentBlock.put("type", "text");
            contentBlock.put("text", "Explain Apache Camel in one sentence.");
            content.add(contentBlock);

            message.put("content", content);
            messages.add(message);

            rootNode.put("messages", messages);
            rootNode.put("max_tokens", 200);
            rootNode.put("anthropic_version", "bedrock-2023-05-31");

            exchange.getMessage().setBody(mapper.writer().writeValueAsString(rootNode));
            exchange.getMessage().setHeader(BedrockConstants.MODEL_CONTENT_TYPE, "application/json");
            exchange.getMessage().setHeader(BedrockConstants.MODEL_ACCEPT_CONTENT_TYPE, "application/json");
        });

        // Get the list of chunks
        List<String> chunks = result.getMessage().getBody(List.class);

        // Process each chunk
        for (String chunk : chunks) {
            System.out.println("Chunk: " + chunk);
        }
--------------------------------------------------------------------------------

== Dependencies

Maven users will need to add the following dependency to their pom.xml.

*pom.xml*

[source,xml]
---------------------------------------
<dependency>
    <groupId>org.apache.camel</groupId>
    <artifactId>camel-aws-bedrock</artifactId>
    <version>${camel-version}</version>
</dependency>
---------------------------------------

where `$\{camel-version}` must be replaced by the actual version of Camel.


include::spring-boot:partial$starter.adoc[]
