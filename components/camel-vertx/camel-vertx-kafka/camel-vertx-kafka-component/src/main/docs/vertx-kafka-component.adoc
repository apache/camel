= Vert.x Kafka Component
:doctitle: Vert.x Kafka
:shortname: vertx-kafka
:artifactid: camel-vertx-kafka
:description: Sent and receive messages to/from an Apache Kafka broker using vert.x Kafka client
:since: 3.7
:supportlevel: Stable
:component-header: Both producer and consumer are supported
//Manually maintained attributes
:camel-spring-boot-name: vertx-kafka


*Since Camel {since}*

*{component-header}*

The Vert.x Kafka component is used for communicating with
http://kafka.apache.org/[Apache Kafka] message broker using https://vertx.io/docs/vertx-kafka-client/java/[Vert.x Kafka Client].
This allows the component to work in a *full asynchronous* manner that results on *efficiency and better performance* on both sides, *Camel Producer and Camel Consumer*.

[NOTE]
====
This component works very similar to xref:components::kafka-component.adoc[Kafka Component]. However there are some features that this component
does not _yet_  support like storing offsets in idempotent repository and topics patterns.
However, these features may be added later as improvements to this component.
====

[NOTE]
====
Almost all the Kafka configuration for the component are *auto generated* from Kafka Consumer/Producer configurations. It means that for example the Kafka Consumer configuration
`connections.max.idle.ms` will be generated as `connectionsMaxIdleMs` for the endpoint option as well as the component option.
====

[source,xml]
------------------------------------------------------------
<dependency>
    <groupId>org.apache.camel</groupId>
    <artifactId>camel-vertx-kafka</artifactId>
    <version>x.x.x</version>
    <!-- use the same version as your Camel core version -->
</dependency>
------------------------------------------------------------

== URI format

---------------------------
vertx-kafka:topic[?options]
---------------------------

Topic can be support a single topic or multiple topics concatenated with `,`. For example, this simple route will consume some data from Kafka and write it to a file:

[source,java]
---------------------------
from("vertx-kafka/test_topic1,test_topic_2?groupId=group1&autoOffsetReset=earliest&bootstrapServers=kafka1:9092,kafka2:9092")
to("file://queuedirectory");
---------------------------



// component-configure options: START

// component-configure options: END

// component options: START
include::partial$component-configure-options.adoc[]
include::partial$component-endpoint-options.adoc[]
// component options: END

// endpoint options: START

// endpoint options: END


For more information about Producer/Consumer configuration:

http://kafka.apache.org/documentation.html#newconsumerconfigs[http://kafka.apache.org/documentation.html#newconsumerconfigs]
http://kafka.apache.org/documentation.html#producerconfigs[http://kafka.apache.org/documentation.html#producerconfigs]

== Async Consumer and Producer

This component implements the async Consumer and producer.

This allows camel route to consume and produce events asynchronously without blocking any threads.

== Usage

=== Message headers set by the component consumer
The following headers are available when consuming messages from Kafka.

[width="100%",cols="10%,10%,10%,70%",options="header",]
|=======================================================================
|Header |Variable Name |Type |Description

|`CamelVertxKafkaPartitionId`| `VertxKafkaConstants.PARTITION_ID`|`Integer`| The partition identifier where the message were consumed from.
|`CamelVertxKafkaMessageKey`| `VertxKafkaConstants.MESSAGE_KEY`|`String`| The message key.
|`CamelVertxKafkaTopic`| `VertxKafkaConstants.TOPIC`|`String`| The topic from where the message originated.
|`CamelVertxKafkaOffset`| `VertxKafkaConstants.OFFSET`|`Long`| The offset of the message in Kafka topic.
|`CamelVertxKafkaHeaders`| `VertxKafkaConstants.HEADERS`|`List<io.vertx.kafka.client.producer.KafkaHeader>`| The record Kafka headers.
|`CamelVertxKafkaTimestamp`| `VertxKafkaConstants.TIMESTAMP`|`Long`| The timestamp of this record.
|=======================================================================

=== Message headers evaluated by the component producer
Before sending a message to Kafka you can configure the following headers.

[width="100%",cols="10%,10%,10%,70%",options="header",]
|=======================================================================
|Header |Variable Name |Type |Description

|`CamelVertxKafkaPartitionId`| `VertxKafkaConstants.PARTITION_ID`|`Integer`| Explicitly specify the partition identifier, for example partition `0`. This will trigger the component to produce all the massages to the specified partition.
|`CamelVertxKafkaMessageKey`| `VertxKafkaConstants.MESSAGE_KEY`|`String`| Explicitly specify the message key, if partition ID is not specified, this will trigger the messages to go into the same partition.
|`CamelVertxKafkaTopic`| `VertxKafkaConstants.TOPIC`|`String`| Explicitly specify the topic to where produce the messages, this will be *preserved* in case of header aggregation.
|`CamelVertxKafkaOverrideTopic`| `VertxKafkaConstants.OVERRIDE_TOPIC`|`String`| Explicitly specify the topic to where produce the messages, this will *not be preserved* in case of header aggregation and it will take *precedence* over `CamelVertxKafkaTopic`.
| `CamelVertxKafkaOverrideTimestamp` | `VertxKafkaConstants.OVERRIDE_TIMESTAMP` | Long | The ProducerRecord also has an associated timestamp. If the user did provide a timestamp, the producer will stamp the  record with the provided timestamp and the header is not preserved. 
|=======================================================================

If you want to send a message to a dynamic topic then use `VertxKafkaConstants.OVERRIDE_TOPIC` as its used as a one-time header
that are not send along the message, as its removed in the producer.

=== Message headers set by the component producer
After the message is sent to Kafka, the following headers are available

[width="100%",cols="10%,10%,10%,70%",options="header",]
|=======================================================================
|Header |Variable Name |Type |Description

|`CamelVertxKafkaRecordMetadata`| `VertxKafkaConstants.RECORD_METADATA`|`List<io.vertx.kafka.client.producer.RecordMetadata>`| Produced record metadata.
|=======================================================================

=== Message body type
Currently, the component supports the following value serializers for the body message on the producer side:

* `org.apache.kafka.common.serialization.StringSerializer`: *Default* produce the message as `String`.
* `org.apache.kafka.common.serialization.ByteArraySerializer`: Produce the messages as `byte[]`.
* `org.apache.kafka.common.serialization.ByteBufferSerializer` : Produce the messages as `ByteBuffer`.

On the consumer side, Camel will utilize Camel TypeConverter to automatically convert the messages, or you can specify the marshal/unmarshal mechanism in the route.

=== Kafka Headers propagation

When consuming messages from Kafka, Kafka record headers will be propagated to camel exchange headers automatically.
Producing flow backed by same behaviour - camel headers of particular exchange will be propagated to kafka message headers.

Since vertx kafka headers allows only `io.vertx.core.buffer.Buffer` values, in order camel exchnage header to be propagated its value should be serialized to `io.vertx.core.buffer.Buffer` in case the type is not supported by the component, e.g `Float`,
otherwise header will be skipped.

Following header value types are supported when producing the message *from* camel *to* kafka: `String`, `Integer`, `Long`, `Double`, `Boolean`, `byte[]`, `io.vertx.core.buffer.Buffer`.

Note: all headers propagated *from* kafka *to* camel exchange will contain `io.vertx.core.buffer.Buffer` value by default.

Having the support of `io.vertx.core.buffer.Buffer` header type, will allow you un-wrap the header to any type without much knowledge in `byte[]`. For example:

[source,java]
----
from("direct")
    .process(exchange -> {
        // set kafka header
        exchange.getIn().setHeader("MyHeader", 2.0);
        exchange.getIn().setBody("test event");
})
.to("vertx-kafka:test_topic?bootstrapServers=kafka9092")
----
Then later:

[source,java]
----
from("vertx-kafka:test_topic?bootstrapServers=kafka9092")
    .process(exchange -> {
        // get our kafka header
        Buffer headerBuffer = exchange.getIn().getHeader("MyHeader");
        System.out.println(headerBuffer.getDouble(0); // it will print 2.0
})
.to("direct)
----

By default all headers are being filtered by `VertxKafkaHeaderFilterStrategy`.
Strategy filters out headers which start with `Camel` or `org.apache.camel` prefixes.


== Using manual commit with Kafka consumer

By default the Kafka consumer will use auto commit, where the offset will be committed automatically in the background using a given interval.

In case you want to force manual commits, you can use `VertxKafkaManualCommit` API from the Camel Exchange, stored on the message header.
This requires to turn on manual commits by either setting the option `allowManualCommit` to `true` on the `VertxKafkaComponent`
or on the endpoint, for example:

[source,java]
----
VertxKafkaComponent kafka = new VertxKafkaComponent();
kafka.setAllowManualCommit(true);
...
camelContext.addComponent("vertx-kafka", kafka);
----

You can then use the `VertxKafkaManualCommit` from Java code such as a Camel `Processor`:
[source,java]
----
public void process(Exchange exchange) {
    VertxKafkaManualCommit manual =
        exchange.getIn().getHeader(VertxKafkaConstants.MANUAL_COMMIT, VertxKafkaManualCommit.class);
    manual.commit();
}
----

This will force a asynchronous commit to Kafka.

If you want to use a custom implementation of `VertxKafkaManualCommit` then you can configure a custom `VertxKafkaManualCommitFactory`
on the `VertxKafkaComponent` that creates instances of your custom implementation.

=== Consumer Example
Here is the minimal route you need in order to read messages from Kafka.

[source,java]
----
from("vertx-kafka:test?bootstrapServers=localhost:9092")
    .log("Message received from Kafka : ${body}")
    .log("    on the topic ${headers[VertxKafkaConstants.TOPIC]}")
    .log("    on the partition ${headers[VertxKafkaConstants.PARTITION_ID]}")
    .log("    with the offset ${headers[VertxKafkaConstants.OFFSET]}")
    .log("    with the key ${headers[VertxKafkaConstants.MESSAGE_KEY]}")
----

If you need to consume messages from multiple topics you can use a comma separated list of topic names

[source,java]
----
from("vertx-kafka:test1,test2?bootstrapServers=localhost:9092")
    .log("Message received from Kafka : ${body}")
    .log("    on the topic ${headers[VertxKafkaConstants.TOPIC]}")
    .log("    on the partition ${headers[VertxKafkaConstants.PARTITION_ID]}")
    .log("    with the offset ${headers[VertxKafkaConstants.OFFSET]}")
    .log("    with the key ${headers[VertxKafkaConstants.MESSAGE_KEY]}")
----

=== Producer Example

Here is the minimal route you need in order to write messages to Kafka.

[source,java]
----
from("direct")
    .process(exchange -> {
        // set kafka header
        exchange.getIn().setHeader("MyHeader", 2.0);
        // set message key
        exchange.getIn().setHeader(VertxKafkaConstants.MESSAGE_KEY, "123456");
        // set message body
        exchange.getIn().setBody("test event");
})
.to("vertx-kafka:test_topic?bootstrapServers=kafka9092")
----

Also, the component supports as well *aggregation* of messages by sending events as *iterable* of either Exchanges/Messages or normal data (e.g: list of Strings). For example:

[source,java]
----
from("direct:start")
.process(exchange -> {
        final List<String> messages = new LinkedList<>();
        messages.add("Test String Message 1");
        messages.add("Test String Message 2");
        // send our messages to partition 0
        exchange.getIn().setHeader(VertxKafkaConstants.PARTITION_ID, 0);
        // set message body
        exchange.getIn().setBody(messages);
})
.to("vertx-kafka:test_topic?bootstrapServers=kafka9092")
----



include::spring-boot:partial$starter.adoc[]
