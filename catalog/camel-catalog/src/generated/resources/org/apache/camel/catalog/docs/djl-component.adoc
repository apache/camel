[[djl-component]]
= Deep Java Library Component
:docTitle: Deep Java Library
:artifactId: camel-djl
:description: Infer Deep Learning models from message exchanges data using Deep Java Library (DJL).
:since: 3.3
:supportLevel: Stable
:component-header: Only producer is supported
include::{cq-version}@camel-quarkus:ROOT:partial$reference/components/djl.adoc[opts=optional]

*Since Camel {since}*

*{component-header}*

The *Deep Java Library* component is used to infer Deep Learning models from message exchanges data.
This component uses https://djl.ai/[Deep Java Library] as underlying library.

In order to use the DJL component, Maven users will need to add the
following dependency to their `pom.xml`:

*pom.xml*

[source,xml]
----
<dependency>
    <groupId>org.apache.camel</groupId>
    <artifactId>camel-djl</artifactId>
    <version>x.x.x</version>
    <!-- use the same version as your Camel core version -->
</dependency>
----

== URI format

[source,text]
----
djl:application
----

You can append query options to the URI in the following format,
`?option=value&option=value&...`

// component options: START
The Deep Java Library component supports 2 options, which are listed below.



[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *lazyStartProducer* (producer) | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | boolean
| *autowiredEnabled* (advanced) | Whether autowiring is enabled. This is used for automatic autowiring options (the option must be marked as autowired) by looking up in the registry to find if there is a single instance of matching type, which then gets configured on the component. This can be used for automatic configuring JDBC data sources, JMS connection factories, AWS Clients, etc. | true | boolean
|===
// component options: END

The DJL component only supports producer endpoints.

// endpoint options: START
The Deep Java Library endpoint is configured using URI syntax:

----
djl:application
----

with the following path and query parameters:

=== Path Parameters (1 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *application* | *Required* Application name |  | String
|===


=== Query Parameters (5 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Type
| *artifactId* (producer) | Model Artifact |  | String
| *lazyStartProducer* (producer) | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | boolean
| *model* (producer) | Model |  | String
| *translator* (producer) | Translator |  | String
| *synchronous* (advanced) | Sets whether synchronous processing should be strictly used, or Camel is allowed to use asynchronous processing (if supported). | false | boolean
|===
// endpoint options: END


== Model Zoo

The following table contains supported models in the model zoo:

[width="100%",cols="1,3,5,3,5,5",options="header"]
|===
| CV | Image  Classification | Resnet image classification | `cv/image_classification` | `ai.djl.zoo:resnet:0.0.1` | {layers=50, flavor=v1, dataset=cifar10}
| CV | Image  Classification | MLP image classification | `cv/image_classification` | `ai.djl.zoo:mlp:0.0.2` | {dataset=mnist}
| CV | Image  Classification | MLP image classification | `cv/image_classification` | `ai.djl.mxnet:mlp:0.0.1` | {dataset=mnist}
| CV | Image  Classification | Resnet image classification | `cv/image_classification` | `ai.djl.mxnet:resnet:0.0.1` | {layers=18, flavor=v1, dataset=imagenet}
| CV | Image  Classification | Resnet image classification | `cv/image_classification` | `ai.djl.mxnet:resnet:0.0.1` | {layers=50, flavor=v2, dataset=imagenet}
| CV | Image  Classification | Resnet image classification | `cv/image_classification` | `ai.djl.mxnet:resnet:0.0.1` | {layers=152, flavor=v1d, dataset=imagenet}
| CV | Image  Classification | Resnet image classification | `cv/image_classification` | `ai.djl.mxnet:resnet:0.0.1` | {layers=50, flavor=v1, dataset=cifar10}
| CV | Image  Classification | Resnext image classification | `cv/image_classification` | `ai.djl.mxnet:resnext:0.0.1` | {layers=101, flavor=64x4d, dataset=imagenet}
| CV | Image  Classification | Senet image classification | `cv/image_classification` | `ai.djl.mxnet:senet:0.0.1` | {layers=154, dataset=imagenet}
| CV | Image  Classification | Senet and Resnext image classification | `cv/image_classification` | `ai.djl.mxnet:se_resnext:0.0.1` | {layers=101, flavor=32x4d, dataset=imagenet}
| CV | Image  Classification | Senet and Resnext image classification | `cv/image_classification` | `ai.djl.mxnet:se_resnext:0.0.1` | {layers=101, flavor=64x4d, dataset=imagenet}
| CV | Image  Classification | Squeezenet image classification | `cv/image_classification` | `ai.djl.mxnet:squeezenet:0.0.1` | {flavor=1.0, dataset=imagenet}
| CV | Object  Detection | Single Shot Detection for Object Detection | `cv/object_detection` | `ai.djl.zoo:ssd:0.0.1` | {flavor=tiny, dataset=pikachu}
| CV | Object  Detection | Single-shot object detection | `cv/object_detection` | `ai.djl.mxnet:ssd:0.0.1` | {size=512, backbone=resnet50, flavor=v1, dataset=voc}
| CV | Object  Detection | Single-shot object detection | `cv/object_detection` | `ai.djl.mxnet:ssd:0.0.1` | {size=512, backbone=vgg16, flavor=atrous, dataset=coco}
| CV | Object  Detection | Single-shot object detection | `cv/object_detection` | `ai.djl.mxnet:ssd:0.0.1` | {size=512, backbone=mobilenet1.0, dataset=voc}
| CV | Object  Detection | Single-shot object detection | `cv/object_detection` | `ai.djl.mxnet:ssd:0.0.1` | {size=300, backbone=vgg16, flavor=atrous, dataset=voc}
|===


== DJL Engine implementation

Because DJL is deep learning framework agnostic, you don't have to make a choice between frameworks when creating your projects.
You can switch frameworks at any point.
To ensure the best performance, DJL also provides automatic CPU/GPU choice based on hardware configuration.

=== MxNet engine

You can pull the MXNet engine from the central Maven repository by including the following dependency:

[source,xml]
----
<dependency>
    <groupId>ai.djl.mxnet</groupId>
    <artifactId>mxnet-engine</artifactId>
    <version>x.x.x</version>
    <scope>runtime</scope>
</dependency>
----

DJL offers an automatic option that will download the jars the first time you run DJL.
It will automatically determine the appropriate jars for your system based on the platform and GPU support.

[source,xml]
----
    <dependency>
      <groupId>ai.djl.mxnet</groupId>
      <artifactId>mxnet-native-auto</artifactId>
      <version>1.7.0-a</version>
      <scope>runtime</scope>
    </dependency>
----

More information about https://github.com/awslabs/djl/blob/master/mxnet/mxnet-engine/README.md#installation[MxNet engine installation]

=== PyTorch engine

You can pull the PyTorch engine from the central Maven repository by including the following dependency:

[source,xml]
----
<dependency>
    <groupId>ai.djl.pytorch</groupId>
    <artifactId>pytorch-engine</artifactId>
    <version>x.x.x</version>
    <scope>runtime</scope>
</dependency>
----

DJL offers an automatic option that will download the jars the first time you run DJL.
It will automatically determine the appropriate jars for your system based on the platform and GPU support.

[source,xml]
----
    <dependency>
      <groupId>ai.djl.pytorch</groupId>
      <artifactId>pytorch-native-auto</artifactId>
      <version>1.5.0</version>
      <scope>runtime</scope>
    </dependency>
----

More information about https://github.com/awslabs/djl/blob/master/pytorch/pytorch-engine/README.md#installation[PyTorch engine installation]

=== Tensorflow engine

You can pull the Tensorflow engine from the central Maven repository by including the following dependency:

[source,xml]
----
<dependency>
    <groupId>ai.djl.tensorflow</groupId>
    <artifactId>tensorflow-engine</artifactId>
    <version>x.x.x</version>
    <scope>runtime</scope>
</dependency>
----

DJL offers an automatic option that will download the jars the first time you run DJL.
It will automatically determine the appropriate jars for your system based on the platform and GPU support.

[source,xml]
----
    <dependency>
      <groupId>ai.djl.tensorflow</groupId>
      <artifactId>tensorflow-native-auto</artifactId>
      <version>2.1.0</version>
      <scope>runtime</scope>
    </dependency>
----

More information about https://github.com/awslabs/djl/tree/master/tensorflow#installation[Tensorflow engine installation]



== Examples

=== MNIST image classification from file

[source,java]
----
from("file:/data/mnist/0/10.png")
    .to("djl:cv/image_classification?artifactId=ai.djl.mxnet:mlp:0.0.1");
----

=== Object detection
[source,java]
----
from("file:/data/mnist/0/10.png")
    .to("djl:cv/image_classification?artifactId=ai.djl.mxnet:mlp:0.0.1");
----

=== Custom deep learning model
[source,java]
----
// create deep learning model
Model model = Model.newInstance();
model.setBlock(new Mlp(28 * 28, 10, new int[]{128, 64}));
model.load(Paths.get(MODEL_DIR), MODEL_NAME);

// create translator for pre-processing and postprocessing
ImageClassificationTranslator.Builder builder = ImageClassificationTranslator.builder();
builder.setSynsetArtifactName("synset.txt");
builder.setPipeline(new Pipeline(new ToTensor()));
builder.optApplySoftmax(true);
ImageClassificationTranslator translator = new ImageClassificationTranslator(builder);

// Bind model and translator beans
context.getRegistry().bind("MyModel", model);
context.getRegistry().bind("MyTranslator", translator);

from("file:/data/mnist/0/10.png")
    .to("djl:cv/image_classification?model=MyModel&translator=MyTranslator");
----
