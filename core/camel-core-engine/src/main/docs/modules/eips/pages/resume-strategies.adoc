= Resume Strategies
:doctitle: Resume Strategies
:shortname: resume
:description: Provide strategies to allow consuming data from specific offsets
:since: 3.16.0
:supportlevel: Experimental

The resume strategies allow users to implement strategies that point the consumer part of the routes to the last point of consumption. This allows Camel to skip reading and processing data that has already been consumed.

The resume strategies can be used to allow quicker stop and resume operations when consuming large data sources. For instance, imagine a scenario where the file consumer is reading a large file. Without a resume strategy, stopping and starting Camel would cause the consumer in the File component to read all the bytes of the given file at the initial offset (offset 0). The resume strategy allow integrations can point the consumer to the exact offset to resume the operations.

Support for resume varies according to the component. Initially, the support is available for the following components:

* xref:components::atom-component.adoc[camel-atom]
* xref:components::aws2-kinesis-component.adoc[camel-aws2-kinesis]
* xref:components::couchdb-component.adoc[camel-couchdb]
* xref:components::file-component.adoc[camel-file]
* xref:components::kafka-component.adoc[camel-kafka]
* xref:components::rss-component.adoc[camel-rss]

The resume strategies comes in 3 parts:

* A DSL method that marks the route as supporting resume operations and points to an instance of a strategy implementation.
* A set of core infrastructure that allow integrations to implement different types of strategies
* Basic strategies implementations that can be extended to implement the specific resume strategies required by the integrations

== The DSL method

The route needs to use the `resumable()` method followed by a `resumableStrategy` to point to an instance of the resume strategy in use.

This instance can be bound in the Context registry as follows:

[source,java]
----
getCamelContext().getRegistry().bind("testResumeStrategy", new MyTestResumeStrategy());

from("some:component")
    .resumable("testResumeStrategy")
    .process(this::process);
----

Or the instance can be constructed as follows:

[source,java]
----
from("some:component")
    .resumable(new MyTestResumeStrategy())
    .process(this::process)
----

== The Resume API Interfaces

These are the *core interfaces*:

* `org.apache.camel.ResumeStrategy` - the basic resume strategy
* `org.apache.camel.UpdatableConsumerResumeStrategy` - an extension to the resume strategy to allow updatable strategies
* `org.apache.camel.ResumeCache` - an interface for local cache for resumable information

These are the *core classes* supporting the strategies:

* `org.apache.camel.Resumable` - an interface to allow users to work with abstract resumable entities (files, offsets, etc)
* `org.apache.camel.ResumableSet` - an interface for resumables with a 1-to-many relationship
* `org.apache.camel.Offset` - a generic offset without a concrete type (it may represent a long, a file name, etc)

These are the *supporting classes*:

* `org.apache.camel.support.Resumables` - resumables handling support
* `org.apache.camel.support.Offsets` - offset handling support

== Basic Strategies

The basic strategies offer a component-specific skeleton that can be used to implement strategies.

* `AbstractKafkaResumeStrategy` - a resume strategy from the `camel-kafka` component that uses Kafka as the store for the offsets.

[source,java]
----
public class KafkaResumeStrategy<K> extends AbstractKafkaResumeStrategy<K, Long> implements GenericFileResumeStrategy<File> {

    private static final Logger LOG = LoggerFactory.getLogger(KafkaResumeStrategy.class);
    public static final int CACHE_SIZE = 100;

    private final String topic;
    private final ResumeCache<K, Long> cache;

    public KafkaResumeStrategy(String topic,
                               ResumeCache<K, Long> cache,
                               DefaultProducerPropertyFactory producerPropertyFactory,
                               DefaultConsumerPropertyFactory consumerPropertyFactory)
    {
        super(topic, cache, producerPropertyFactory.getProperties(), consumerPropertyFactory.getProperties());
        this.topic = topic;
        this.cache = cache;
    }


    private Optional<Long> getLastOffset(GenericFileResumable<File> resumable) {
        final File addressable = resumable.getAddressable();
        return getLastOffset((K) addressable);
    }

    public Optional<Long> getLastOffset(K addressable) {
        return cache.get(addressable);
    }

    @Override
    public void subscribe() {
        checkAndSubscribe(topic, 1);
    }

    @Override
    public void resume(GenericFileResumable<File> resumable) {
        final Optional<Long> lastOffsetOpt = getLastOffset(resumable);

        if (!lastOffsetOpt.isPresent()) {
            return;
        }

        final long lastOffset = lastOffsetOpt.get();
        resumable.updateLastOffset(lastOffset);
    }

    @Override
    public void resume() {
        throw new UnsupportedOperationException("Cannot perform blind resume");
    }
}
----


== Local Cache Support

A sample local cache implemented using https://github.com/ben-manes/caffeine[Caffeine].

[source,java]
----
public class SingleItemCache<K> implements ResumeCache<K, Long> {
    public static final int CACHE_SIZE = 100;
    private final Cache<K, Long> cache = Caffeine.newBuilder()
            .maximumSize(CACHE_SIZE)
            .build();

    @Override
    public void add(K key, Long offsetValue) {
        cache.put(key, offsetValue);
    }

    @Override
    public Optional<Long> get(K key) {
        Long entry = cache.getIfPresent(key);

        if (entry == null) {
            return Optional.empty();
        }

        return Optional.of(entry.longValue());
    }

    @Override
    public boolean isFull() {
        if (cache.estimatedSize() < CACHE_SIZE) {
            return true;
        }

        return false;
    }
}
----


== Known Limitations

When using the converters with the file component, beware of the differences in the behavior from `Reader` and `InputStream`:

For instance, the behavior of:

[source,java]
----
from("file:{{input.dir}}?noop=true&fileName={{input.file}}")
    .resumable("testResumeStrategy")
    .convertBodyTo(Reader.class)
    .process(this::process);
----

Is different from the behavior of:

[source,java]
----
from("file:{{input.dir}}?noop=true&fileName={{input.file}}")
    .resumable("testResumeStrategy")
    .convertBodyTo(InputStream.class)
    .process(this::process);
----

*Reason*: the `skip` method in the Reader will skip characters, whereas the same method on the InputStream will skip bytes.


== Pausable Consumers API

The Pausable consumers API is a subset of the resume API that provides pause and resume features for supported components.
With this API it is possible to implement logic that controls the behavior of the consumer based on conditions that are
external to the component. For instance, it makes it possible to pause the consumer if an external system becomes unavailable.

Currently, support for pausable consumers is available for the following components:

* xref:components::kafka-component.adoc[camel-kafka]

To use the API, it needs an instance of a Consumer listener along with a predicate that tests whether to continue.

* `org.apache.camel.ConsumerListener` - the consumer listener interface. Camel already comes with pre-built consumer listeners, but users in need of more complex behaviors can create their own listeners.
* a predicate that returns true if data consumption should resume or false if consumption should be put on pause

Usage example:

[source,java]
----
from(from)
    .pausable(new KafkaConsumerListener(), o -> canContinue())
    .process(exchange -> LOG.info("Received an exchange: {}", exchange.getMessage().getBody()))
    .to(destination);
----

You can also integrate the pausable API and the consumer listener with the circuit breaker EIP. For instance, it's
possible to configure the circuit breaker so that it can manipulate the state of the listener based on success or on
error conditions on the circuit.

One example, would be to create a event watcher that checks for a downstream system availability. It watches for error events and, when they happen, it triggers a scheduled check. On success, it shuts down the scheduled check.

An example implementation of this approach would be similar to this:

[source,java]
----
CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults("pausable");

circuitBreaker.getEventPublisher()
    .onSuccess(event -> {
        LOG.info("Downstream call succeeded");
        if (executorService != null) {
            executorService.shutdownNow();
            executorService = null;
        }
    })
    .onError(event -> {
        LOG.info(
                "Downstream call error. Starting a thread to simulate checking for the downstream availability");

        if (executorService == null) {
            executorService = Executors.newSingleThreadScheduledExecutor();
            // In a real world scenario, instead of incrementing, it could be pinging a remote system or
            // running a similar check to determine whether it's available. That
            executorService.scheduleAtFixedRate(() -> someCheckMethod(), 1, 1, TimeUnit.SECONDS);
        }
    });

// Binds the configuration to the registry
 getCamelContext().getRegistry().bind("pausableCircuit", circuitBreaker);

from(from)
    .pausable(new KafkaConsumerListener(), o -> canContinue())
    .routeId("pausable-it")
    .process(exchange -> LOG.info("Got record from Kafka: {}", exchange.getMessage().getBody()))
    .circuitBreaker()
        .resilience4jConfiguration().circuitBreaker("pausableCircuit").end()
        .to(to)
    .end();
----
