
// AUTO-GENERATED by camel-package-maven-plugin - DO NOT EDIT THIS FILE
= camel explain

Explain what a Camel route does using AI/LLM


== Usage

[source,bash]
----
camel explain [options]
----



== Options

[cols="2,5,1,2",options="header"]
|===
| Option | Description | Default | Type
| `--api-key` | API key for authentication. Also reads OPENAI_API_KEY or LLM_API_KEY env vars |  | String
| `--api-type` | API type: 'ollama' or 'openai' (OpenAI-compatible) | ollama | ApiType
| `--catalog-context` | Include Camel Catalog descriptions in the prompt |  | boolean
| `--format` | Output format: text, markdown | text | String
| `--model` | Model to use | DEFAULT_MODEL | String
| `--show-prompt` | Show the prompt sent to the LLM |  | boolean
| `--stream` | Stream the response as it's generated (shows progress) | true | boolean
| `--system-prompt` | Custom system prompt |  | String
| `--temperature` | Temperature for response generation (0.0-2.0) | 0.7 | double
| `--timeout` | Timeout in seconds for LLM response | 120 | int
| `--url` | LLM API endpoint URL. Auto-detected from 'camel infra' for Ollama if not specified. |  | String
| `--verbose,-v` | Include detailed technical information |  | boolean
| `-h,--help` | Display the help and sub-commands |  | boolean
|===



include::partial$jbang-commands/examples/explain.adoc[]

